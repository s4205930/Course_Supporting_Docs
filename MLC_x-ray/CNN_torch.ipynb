{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc440994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score,\n",
    "    hamming_loss, accuracy_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights, DenseNet121_Weights, efficientnet_b0, EfficientNet_B0_Weights, efficientnet_b3, EfficientNet_B3_Weights, ResNet34_Weights, convnext_base, ConvNeXt_Base_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35486a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_dir, image_dir, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        df = pd.read_csv(csv_dir)\n",
    "\n",
    "        # Extract labels and image names\n",
    "        self.labels = df.iloc[:, -14:].values.astype(\"float32\")\n",
    "        self.image_names = df['Path'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_names[idx])\n",
    "\n",
    "        try:\n",
    "            # image = Image.open(img_path).convert('L')  # Grayscale\n",
    "            image = Image.open(img_path).convert('RGB')  # RGB\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {img_path} - {e}\")\n",
    "            raise e\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "\n",
    "        image = np.array(image)\n",
    "\n",
    "        label = np.array(self.labels[idx])\n",
    "        \n",
    "        return {'images': image, 'labels': label}\n",
    "\n",
    "def compute_sample_weights(labels):\n",
    "    \"\"\"\n",
    "    Computes sample weights for multi-label oversampling.\n",
    "    labels: numpy array of shape (N, num_classes)\n",
    "    \"\"\"\n",
    "    label_counts = np.sum(labels, axis=0)  # count per class\n",
    "    class_weights = 1.0 / (label_counts + 1e-6)  # avoid division by zero\n",
    "\n",
    "    # Sample weights per image: mean of the weights of the labels present\n",
    "    sample_weights = np.dot(labels, class_weights)\n",
    "    return sample_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 224\n",
    "size = (dim, dim)\n",
    "\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.Resize(size),                      # Resize first\n",
    "    transforms.RandomHorizontalFlip(p=0.5),      # 50% chance flip\n",
    "    transforms.RandomRotation(15),                # Â±15 degrees rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # brightness/contrast jitter\n",
    "    transforms.RandomResizedCrop(size, scale=(0.8, 1.0)),  # random zoom/crop\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5), # optional perspective distortion\n",
    "    transforms.Grayscale(num_output_channels=3), # convert to 3 channel grayscale\n",
    "    transforms.ToTensor(),                         # convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalisation standard\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "ds_size = \"Balanced\"\n",
    "\n",
    "train_data = ImageDataset(fr\"NIH_X_14_{ds_size}\\train_labels_encoded.csv\", fr\"NIH_X_14_{ds_size}\\train\", transforms=trans_train)\n",
    "test_data = ImageDataset(fr\"NIH_X_14_{ds_size}\\test_labels_encoded.csv\", fr\"NIH_X_14_{ds_size}\\test\", transforms=trans_val)\n",
    "val_data = ImageDataset(fr\"NIH_X_14_{ds_size}\\val_labels_encoded.csv\", fr\"NIH_X_14_{ds_size}\\val\", transforms=trans_val)\n",
    "\n",
    "\n",
    "class_names = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "    'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n",
    "    'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62464462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute sample weights from label frequency ---\n",
    "label_array = np.array(train_data.labels)  # Shape: (N_samples, N_classes)\n",
    "class_counts = np.sum(label_array, axis=0)  # total positives per class\n",
    "class_weights = 1.0 / (class_counts + 1e-6)  # inverse frequency\n",
    "class_weights = class_weights / np.sum(class_weights) * len(class_weights)  # normalize\n",
    "\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Class weights (normalized):\", np.round(class_weights, 4))\n",
    "\n",
    "sample_weights = np.dot(label_array, class_weights)  # (N_samples,)\n",
    "sample_weights = sample_weights / np.sum(sample_weights) * len(sample_weights)\n",
    "sample_weights = np.clip(sample_weights, a_min=1e-6, a_max=None)\n",
    "\n",
    "print(f\"Sample weights: mean={sample_weights.mean():.4e}, std={sample_weights.std():.4e}, max={sample_weights.max():.4e}\")\n",
    "\n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "if imbalance_ratio > 10:\n",
    "    print(f\"Warning: Significant class imbalance detected (max/min = {imbalance_ratio:.2f}). Consider data augmentation or other sampling strategies.\")\n",
    "\n",
    "sample_weights_tensor = torch.DoubleTensor(sample_weights)\n",
    "sampler = WeightedRandomSampler(sample_weights_tensor, len(sample_weights_tensor), replacement=True)\n",
    "\n",
    "# Sanity check\n",
    "unique_indices = set([i for i in sampler])\n",
    "if len(unique_indices) < 0.5 * len(train_data):\n",
    "    print(f\"Sampler is using only {len(unique_indices)} unique samples out of {len(train_data)}. Check weights.\")\n",
    "\n",
    "# --- DataLoaders ---\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, sampler=sampler, drop_last=True, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True, pin_memory=True)\n",
    "val_dl = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet_fine_tune(self, n_layers):\n",
    "    for param in self.net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    res_layers = [self.net.layer1, self.net.layer2, self.net.layer3, self.net.layer4]\n",
    "    for block in res_layers[-n_layers:]:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    for param in self.net.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def _efficientnet_fine_tune(self, n_layers):\n",
    "    for param in self.model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    for block in self.model.features[-n_layers:]:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "    for param in self.model.classifier.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.net = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            self.net.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.in_features = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(self.in_features, num_classes)\n",
    "\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.net.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.model_name = \"ResNet50\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def fine_tune(self, n_layers=2):\n",
    "        _resnet_fine_tune(self, n_layers)\n",
    "\n",
    "# ResNet34\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.net = models.resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            self.net.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.in_features = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(self.in_features, num_classes)\n",
    "\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.net.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.model_name = \"ResNet34\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def fine_tune(self, n_layers=2):\n",
    "        _resnet_fine_tune(self, n_layers)\n",
    "\n",
    "# ResNet18\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.net = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            self.net.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.in_features = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(self.in_features, num_classes)\n",
    "\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.net.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.model_name = \"ResNet18\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def fine_tune(self, n_layers=2):\n",
    "        _resnet_fine_tune(self, n_layers)\n",
    "\n",
    "# DenseNet121\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        base_model = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            base_model.features.conv0 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.features = base_model.features\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        in_features = base_model.classifier.in_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Freeze everything\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.model_name = \"DenseNet121\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def fine_tune(self, n_layers=2):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        blocks = [self.features.denseblock1, self.features.denseblock2, self.features.denseblock3, self.features.denseblock4]\n",
    "        for block in blocks[-n_layers:]:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = True\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# EfficientNetB0\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3, freeze=True):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            old_conv = self.model.features[0][0]\n",
    "            self.model.features[0][0] = nn.Conv2d(\n",
    "                in_channels=in_chans,\n",
    "                out_channels=old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                bias=old_conv.bias is not None\n",
    "            )\n",
    "        self.model_name = \"EfficientNetB0\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def fine_tune(self, n_layers=2):\n",
    "        _efficientnet_fine_tune(self, n_layers)\n",
    "\n",
    "# EfficientNetB3\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3, freeze=True):\n",
    "        super(EfficientNetB3, self).__init__()\n",
    "        self.model = efficientnet_b3(weights=EfficientNet_B3_Weights.DEFAULT)\n",
    "        if in_chans != 3:\n",
    "            old_conv = self.model.features[0][0]\n",
    "            self.model.features[0][0] = nn.Conv2d(\n",
    "                in_channels=in_chans,\n",
    "                out_channels=old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                bias=old_conv.bias is not None\n",
    "            )\n",
    "        self.model_name = \"EfficientNetB3\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def fine_tune(self, n_layers=2):\n",
    "        _efficientnet_fine_tune(self, n_layers)\n",
    "\n",
    "# ConvNeXt\n",
    "class ConvNeXtBase(nn.Module):\n",
    "    def __init__(self, num_classes, in_chans=3, freeze=True):\n",
    "        super(ConvNeXtBase, self).__init__()\n",
    "        self.model = convnext_base(weights=ConvNeXt_Base_Weights.DEFAULT)\n",
    "\n",
    "        if in_chans != 3:\n",
    "            old_conv = self.model.features[0][0]\n",
    "            self.model.features[0][0] = nn.Conv2d(\n",
    "                in_chans,\n",
    "                old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                bias=False\n",
    "            )\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.classifier[2].in_features\n",
    "        self.model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.model_name = \"ConvNeXtBase\"\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def fine_tune(self, n_layers=2):\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for block in self.model.features[-n_layers:]:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = True\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = self.bce(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "def optimise_thresholds(all_targets, all_probs):\n",
    "    best_thresholds = []\n",
    "\n",
    "    for i in range(all_targets.shape[1]):\n",
    "        scores = []\n",
    "        for t in tqdm(np.arange(0, 1, 0.01), desc=f\"Optimising threshold of class {i+1}\"):\n",
    "            probs = (all_probs[:, i] > t).astype(int)\n",
    "            f1 = f1_score(all_targets[:, i], probs, zero_division=0)\n",
    "            scores.append((t, f1))\n",
    "        best_threshold = max(scores, key=lambda x: x[1])[0]\n",
    "        best_thresholds.append(best_threshold)\n",
    "    \n",
    "    return best_thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(num_classes=14)\n",
    "model = model.to(device)\n",
    "\n",
    "eta = 1e-4\n",
    "opti = torch.optim.AdamW(model.parameters(), lr=eta, weight_decay=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbe0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "\n",
    "epoch_train_loss, epoch_val_loss = [], []\n",
    "val_roc_aucs_by_epoch, val_roc_auc_means = [], []\n",
    "hammings, precisions, recalls, f1_macros, f1_micros = [], [], [], [], []\n",
    "class_thresholds = np.full(14, 0.35)\n",
    "best_auc = 0.0\n",
    "early_stop_counter = 0\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_log = []\n",
    "metrics_csv_path = f\"Metrics/{model.model_name}_training_metrics.csv\"\n",
    "os.makedirs(os.path.dirname(metrics_csv_path), exist_ok=True)\n",
    "os.makedirs(\"Checkpoints\", exist_ok=True)  # Ensure checkpoint folder exists\n",
    "\n",
    "roc_auc_columns = [f\"roc_auc_{name}\" for name in class_names]\n",
    "\n",
    "# Write header if file doesn't exist\n",
    "if not os.path.exists(metrics_csv_path):\n",
    "    with open(metrics_csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\", \"train_loss\", \"val_loss\", \"mean_auc\", \"mean_entropy\",\n",
    "            \"f1_micro\", \"f1_macro\", \"precision\", \"recall\", \"hamming_loss\"\n",
    "        ] + roc_auc_columns)\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "\n",
    "    for d in tqdm(train_dl, desc=f\"Training {epoch+1}/{epochs}\"):\n",
    "        opti.zero_grad()\n",
    "        imgs = d['images'].to(device, dtype=torch.float)\n",
    "        labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        opti.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    epoch_train_loss.append(np.mean(train_losses))\n",
    "    model.epochs_trained += 1\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses, val_preds, val_targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(val_dl, desc=\"Validating\"):\n",
    "            imgs = d['images'].to(device, dtype=torch.float)\n",
    "            labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            val_preds.append(preds.cpu())\n",
    "            val_targets.append(labels.cpu())\n",
    "\n",
    "    epoch_val_loss.append(np.mean(val_losses))\n",
    "    all_val_preds = torch.cat(val_preds).numpy()\n",
    "    all_val_targets = torch.cat(val_targets).numpy()\n",
    "\n",
    "    entropy = - (all_val_preds * np.log(all_val_preds + 1e-7) + (1 - all_val_preds) * np.log(1 - all_val_preds + 1e-7))\n",
    "    mean_entropy = np.mean(entropy)\n",
    "\n",
    "    val_epoch_roc_aucs = []\n",
    "    for i in range(all_val_targets.shape[1]):\n",
    "        try:\n",
    "            auc = roc_auc_score(all_val_targets[:, i], all_val_preds[:, i])\n",
    "        except ValueError:\n",
    "            auc = float('nan')\n",
    "        val_epoch_roc_aucs.append(auc)\n",
    "\n",
    "    val_roc_aucs_by_epoch.append(val_epoch_roc_aucs)\n",
    "    mean_auc = np.nanmean(val_epoch_roc_aucs)\n",
    "    val_roc_auc_means.append(mean_auc)\n",
    "\n",
    "    # --- Thresholding ---\n",
    "    binary_preds = np.zeros_like(all_val_preds)\n",
    "    for i, thresh in enumerate(class_thresholds):\n",
    "        binary_preds[:, i] = (all_val_preds[:, i] > thresh).astype(int)\n",
    "\n",
    "    f1_micro = f1_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(all_val_targets, binary_preds, average='macro', zero_division=0)\n",
    "    precision = precision_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    recall = recall_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    hamming = hamming_loss(all_val_targets, binary_preds)\n",
    "    label_accuracy = (binary_preds == all_val_targets).mean(axis=0)\n",
    "\n",
    "    f1_micros.append(f1_micro)\n",
    "    f1_macros.append(f1_macro)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    hammings.append(hamming)\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    print(f\"Train Loss: {epoch_train_loss[-1]:.4f} | Val Loss: {epoch_val_loss[-1]:.4f}\")\n",
    "    print(f\"Mean ROC-AUC: {mean_auc:.4f} | Mean Entropy: {mean_entropy:.4f}\")\n",
    "    print(f\"F1-score (micro): {f1_micro:.4f} | F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "    print(f\"Hamming Loss: {hamming:.4f}\")\n",
    "    print(f\"Label-wise Accuracy: {label_accuracy.round(3)}\\n\")\n",
    "\n",
    "    # Save metrics to CSV using model.epochs_trained\n",
    "    with open(metrics_csv_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            model.epochs_trained,\n",
    "            epoch_train_loss[-1],\n",
    "            epoch_val_loss[-1],\n",
    "            mean_auc,\n",
    "            mean_entropy,\n",
    "            f1_micro,\n",
    "            f1_macro,\n",
    "            precision,\n",
    "            recall,\n",
    "            hamming\n",
    "        ] + val_epoch_roc_aucs)\n",
    "    \n",
    "    # --- Checkpoint & Early Stopping ---\n",
    "    if mean_auc > best_auc:\n",
    "        best_auc = mean_auc\n",
    "        early_stop_counter = 0\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimiser_state_dict': opti.state_dict(),\n",
    "            'epochs_trained': model.epochs_trained,\n",
    "        }, f\"Checkpoints/{model.model_name}_best.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd28338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_probs = []\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(test_dl, desc=\"Generating predictions\"):\n",
    "        imgs = d['images'].to(device, dtype=torch.float)\n",
    "        labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        prob = torch.sigmoid(logits)\n",
    "\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_probs.append(prob.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "        all_images.append(imgs.cpu())\n",
    "\n",
    "# Stack into single arrays\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "all_logits = torch.cat(all_logits).numpy()\n",
    "all_images = torch.cat(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary Training on all layers\n",
    "\n",
    "model.fine_tune()\n",
    "\n",
    "best_thresholds = optimise_thresholds(all_targets, all_probs)\n",
    "\n",
    "new_lr = eta / 10\n",
    "for param_group in opti.param_groups:\n",
    "    param_group['lr'] = new_lr\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "\n",
    "    for d in tqdm(train_dl, desc=f\"Training {epoch+1}/{epochs}\"):\n",
    "        opti.zero_grad()\n",
    "        imgs = d['images'].to(device, dtype=torch.float)\n",
    "        labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        opti.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    epoch_train_loss.append(np.mean(train_losses))\n",
    "    model.epochs_trained += 1\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses, val_preds, val_targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(val_dl, desc=\"Validating\"):\n",
    "            imgs = d['images'].to(device, dtype=torch.float)\n",
    "            labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            val_preds.append(preds.cpu())\n",
    "            val_targets.append(labels.cpu())\n",
    "\n",
    "    epoch_val_loss.append(np.mean(val_losses))\n",
    "    all_val_preds = torch.cat(val_preds).numpy()\n",
    "    all_val_targets = torch.cat(val_targets).numpy()\n",
    "\n",
    "    entropy = - (all_val_preds * np.log(all_val_preds + 1e-7) + (1 - all_val_preds) * np.log(1 - all_val_preds + 1e-7))\n",
    "    mean_entropy = np.mean(entropy)\n",
    "\n",
    "    val_epoch_roc_aucs = []\n",
    "    for i in range(all_val_targets.shape[1]):\n",
    "        try:\n",
    "            auc = roc_auc_score(all_val_targets[:, i], all_val_preds[:, i])\n",
    "        except ValueError:\n",
    "            auc = float('nan')\n",
    "        val_epoch_roc_aucs.append(auc)\n",
    "\n",
    "    val_roc_aucs_by_epoch.append(val_epoch_roc_aucs)\n",
    "    mean_auc = np.nanmean(val_epoch_roc_aucs)\n",
    "    val_roc_auc_means.append(mean_auc)\n",
    "\n",
    "    # --- Thresholding ---\n",
    "    binary_preds = np.zeros_like(all_val_preds)\n",
    "    for i, thresh in enumerate(best_thresholds):\n",
    "        binary_preds[:, i] = (all_val_preds[:, i] > thresh).astype(int)\n",
    "\n",
    "    f1_micro = f1_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(all_val_targets, binary_preds, average='macro', zero_division=0)\n",
    "    precision = precision_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    recall = recall_score(all_val_targets, binary_preds, average='micro', zero_division=0)\n",
    "    hamming = hamming_loss(all_val_targets, binary_preds)\n",
    "    label_accuracy = (binary_preds == all_val_targets).mean(axis=0)\n",
    "\n",
    "    f1_micros.append(f1_micro)\n",
    "    f1_macros.append(f1_macro)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    hammings.append(hamming)\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    print(f\"Train Loss: {epoch_train_loss[-1]:.4f} | Val Loss: {epoch_val_loss[-1]:.4f}\")\n",
    "    print(f\"Mean ROC-AUC: {mean_auc:.4f} | Mean Entropy: {mean_entropy:.4f}\")\n",
    "    print(f\"F1-score (micro): {f1_micro:.4f} | F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "    print(f\"Hamming Loss: {hamming:.4f}\")\n",
    "    print(f\"Label-wise Accuracy: {label_accuracy.round(3)}\\n\")\n",
    "\n",
    "    # Save metrics to CSV using model.epochs_trained\n",
    "    with open(metrics_csv_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            model.epochs_trained,\n",
    "            epoch_train_loss[-1],\n",
    "            epoch_val_loss[-1],\n",
    "            mean_auc,\n",
    "            mean_entropy,\n",
    "            f1_micro,\n",
    "            f1_macro,\n",
    "            precision,\n",
    "            recall,\n",
    "            hamming\n",
    "        ] + val_epoch_roc_aucs)\n",
    "    \n",
    "    # --- Checkpoint & Early Stopping ---\n",
    "    if mean_auc > best_auc:\n",
    "        best_auc = mean_auc\n",
    "        early_stop_counter = 0\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimiser_state_dict': opti.state_dict(),\n",
    "            'epochs_trained': model.epochs_trained,\n",
    "        }, f\"Checkpoints/{model.model_name}_best.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afdb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_loss, label='Train Loss')\n",
    "plt.plot(epoch_val_loss, label='Validation Loss')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(f1_micros, label='F1 Micros')\n",
    "plt.plot(f1_macros, label='F1 Macros')\n",
    "plt.title(\"F1 Scores\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(precisions, label='Precision')\n",
    "plt.plot(recalls, label='Recall')\n",
    "plt.title(\"P&R Rates\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hammings, label='Hamming Loss')\n",
    "plt.title(\"Hamming Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "val_roc_aucs_by_epoch_np = np.array(val_roc_aucs_by_epoch)\n",
    "epochs_range = range(0, len(val_roc_aucs_by_epoch_np))\n",
    "\n",
    "# Per-class curves\n",
    "try:\n",
    "    for i in range(val_roc_aucs_by_epoch_np.shape[1]):\n",
    "        plt.plot(epochs_range, val_roc_aucs_by_epoch_np[:, i], label=class_names[i], alpha=0.5)\n",
    "\n",
    "    # Mean ROC-AUC\n",
    "    plt.plot(epochs_range, val_roc_auc_means, label='Mean ROC-AUC', color='black', linewidth=2.5)\n",
    "\n",
    "    plt.title(\"Validation ROC-AUC per Class and Mean\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"ROC-AUC\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Empty variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9314c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_probs = []\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(test_dl, desc=\"Generating predictions\"):\n",
    "        imgs = d['images'].to(device, dtype=torch.float)\n",
    "        labels = d['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        prob = torch.sigmoid(logits)\n",
    "\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_probs.append(prob.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "        all_images.append(imgs.cpu())\n",
    "\n",
    "# Stack into single arrays\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "all_logits = torch.cat(all_logits).numpy()\n",
    "all_images = torch.cat(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20294f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds = []\n",
    "\n",
    "for i in range(all_targets.shape[1]):\n",
    "    scores = []\n",
    "    for t in tqdm(np.arange(0, 1, 0.01), desc=f\"Optimising threshold of class {i+1}\"):\n",
    "        probs = (all_probs[:, i] > t).astype(int)\n",
    "        f1 = f1_score(all_targets[:, i], probs, zero_division=0)\n",
    "        scores.append((t, f1))\n",
    "    best_threshold = max(scores, key=lambda x: x[1])[0]\n",
    "    best_thresholds.append(best_threshold)\n",
    "\n",
    "print(\"Best thresholds:\", best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.array([\n",
    "    (all_probs[:, i] > best_thresholds[i]).astype(int)\n",
    "    for i in range(all_probs.shape[1])\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs = []\n",
    "\n",
    "for i in range(all_targets.shape[1]):\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    roc_aucs.append(auc)\n",
    "\n",
    "print(\"\\nPer-Class ROC-AUC:\")\n",
    "for i, auc in enumerate(roc_aucs):\n",
    "    print(f\"Class {i}: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\nMacro ROC-AUC: {np.nanmean(roc_aucs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_preds = np.zeros_like(all_preds)\n",
    "\n",
    "for i in range(all_preds.shape[1]):\n",
    "    opti_preds[:, i] = (all_preds[:, i] > best_thresholds[i]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(img_tensor, true_labels, pred_labels, opti_labels, class_names):\n",
    "    # Convert image to numpy array if it's a tensor\n",
    "    if isinstance(img_tensor, torch.Tensor):\n",
    "        img = img_tensor.cpu().numpy()\n",
    "    else:\n",
    "        img = np.array(img_tensor)\n",
    "\n",
    "    # Transpose if image has 3 channels (C, H, W) -> (H, W, C)\n",
    "    if img.ndim == 3 and img.shape[0] == 3:\n",
    "        img = np.transpose(img, (1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "    # Clip values to [0, 1] in case they exceed due to normalisation\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Convert labels to numpy if they're tensors\n",
    "    if isinstance(true_labels, torch.Tensor):\n",
    "        true_labels = true_labels.cpu().numpy()\n",
    "    if isinstance(pred_labels, torch.Tensor):\n",
    "        pred_labels = pred_labels.cpu().numpy()\n",
    "    if isinstance(opti_labels, torch.Tensor):\n",
    "        opti_labels = opti_labels.cpu().numpy()\n",
    "\n",
    "    # Get active labels\n",
    "    true_txt = \", \".join([class_names[i] for i, v in enumerate(true_labels) if v == 1])\n",
    "    pred_txt = \", \".join([class_names[i] for i, v in enumerate(pred_labels) if v == 1])\n",
    "    opti_pred_txt = \", \".join([class_names[i] for i, v in enumerate(opti_labels) if v == 1])\n",
    "\n",
    "    # Plotting\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"True: {true_txt}\\nPred(std): {pred_txt}\\nPred(Opti): {opti_pred_txt}\", fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "idx = random.randint(0, len(all_images)-1)\n",
    "show_prediction(all_images[idx], all_targets[idx], all_preds[idx], opti_preds[idx], class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_acc = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Exact match accuracy: {subset_acc * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimiser_state_dict': opti.state_dict(),\n",
    "            'epochs_trained': model.epochs_trained,\n",
    "        },\n",
    "          f\"Models/{model.model_name}_manual.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39edb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(num_classes=14)\n",
    "checkpoint = torch.load(fr'Checkpoints/{model.model_name}_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opti.load_state_dict(checkpoint['optimiser_state_dict'])\n",
    "model.epochs_trained = checkpoint.get('epochs_trained', 0)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                self.hook_handles.append(module.register_forward_hook(forward_hook))\n",
    "                self.hook_handles.append(module.register_backward_hook(backward_hook))\n",
    "                print(f\"[GradCAM] Hooks registered on layer: {name}\")\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"Layer {self.target_layer} not found in model.\")\n",
    "\n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        loss = output[0, target_class]\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            raise RuntimeError(\"Gradients or activations not captured. Check hook registration.\")\n",
    "\n",
    "        weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "        weighted_activations = weights * self.activations\n",
    "        cam = weighted_activations.sum(dim=1).squeeze()\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        cam -= cam.min()\n",
    "        if cam.max() != 0:\n",
    "            cam /= cam.max()\n",
    "\n",
    "        return cam.cpu().numpy()\n",
    "\n",
    "    def clear_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def run_gradcam_and_save(model, val_dl, target_layer, mean, std, pathology_names=None, save_path=\"gradcam_overlay.png\"):\n",
    "\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "\n",
    "    sample = next(iter(val_dl))\n",
    "    input_tensor = sample['images'][0].unsqueeze(0).to(next(model.parameters()).device)\n",
    "\n",
    "    # Print pathology labels (supports multi-label or single-label)\n",
    "    labels = sample['labels'][0]  # Assume shape [batch, num_classes] or [batch]\n",
    "\n",
    "    if pathology_names:\n",
    "        if labels.ndim == 1 and labels.numel() > 1:\n",
    "            # Multi-label binary vector\n",
    "            present = [pathology_names[i] for i, val in enumerate(labels) if val > 0]\n",
    "            print(\"Pathologies in image:\", \", \".join(present) if present else \"None\")\n",
    "        elif labels.numel() == 1:\n",
    "            # Single-label integer index\n",
    "            print(\"Pathology label:\", pathology_names[labels.item()])\n",
    "        else:\n",
    "            print(\"Labels shape or type unexpected; raw labels:\", labels)\n",
    "    else:\n",
    "        print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    heatmap = grad_cam.generate_cam(input_tensor)\n",
    "\n",
    "    original_img = sample['images'][0].clone()\n",
    "    original_img = unnormalize(original_img, mean, std)\n",
    "    original_img = torch.clamp(original_img, 0, 1)\n",
    "    original_img_np = original_img.permute(1, 2, 0).cpu().numpy()\n",
    "    original_img_np = np.uint8(255 * original_img_np)\n",
    "\n",
    "    heatmap_resized = cv2.resize(heatmap, (original_img_np.shape[1], original_img_np.shape[0]))\n",
    "\n",
    "    heatmap_uint8 = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "\n",
    "    overlayed_img = cv2.addWeighted(original_img_np, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "    cv2.imwrite(save_path, overlayed_img)\n",
    "    print(f\"Grad-CAM overlay saved to {save_path}\")\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(overlayed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    grad_cam.clear_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7db3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "run_gradcam_and_save(model, val_dl, \"features.denseblock4.denselayer16.conv2\", mean, std, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CT6007",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
